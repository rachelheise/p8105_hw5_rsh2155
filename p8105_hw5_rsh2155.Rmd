---
title: "Homework 5"
author: "Rachel Heise"
date: "11/8/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(ggridges)
```
## Problem 1

Import and clean data.
```{r}
homicide_df =
  read_csv("./homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

```{r}
aggregate_df =
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Prop test for a single city

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Iterate

```{r}
results_df =
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)

```


```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Different option for nesting data and writing a function.
```{r, error = TRUE}
city_prop_test = function(df) {
  
  n_unsolved ...
  n_total ...
  
  prop.test(....)
  
}
homicide_df =
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```



## Problem 2

Create dataframe containing names of data files. Add data from each file to dataframe.
```{r}
longitudinal_df =
  tibble(files = list.files("./lda_data/")) %>% 
  mutate(data = map(file.path("./lda_data/", files), read_csv)) %>% 
  unnest(data) %>% 
  pivot_longer(week_1:week_8,
               names_to = "week",
               values_to = "observation") %>% 
  mutate(week = substr(week, 6, 7),
         files = substr(files, 1, 6),
         full_subject = files) %>% 
  separate(files, into = c("arm", "subject_id"), sep = "_")

```


Spaghetti plot
```{r}
longitudinal_df %>% 
  ggplot(aes(x = week, y = observation, group = full_subject, color = arm)) +
  geom_line() +
  labs(
    title = "Observations Over Time for Control & Experimental Arms",
    x = "Week",
    y = "Observation"
  )
```


## Problem 3


for 6 you should reject the null more of the time (conduct the same t test)

```{r, cache = TRUE}
set.seed(1)
t_test_sim = function(samp_size = 30, sigma = 5, mu) {
  
  sim_data = tibble(
    x = rnorm(n = samp_size, mean = mu, sd = sigma)
  )
  
  test = t.test(sim_data, mu = 0)
  
  sim_data %>% 
    summarize(
      est_mean = mean(x),
      p_value = pull(broom::tidy(test), p.value)
  )
}

sim_results = tibble(
  pop_mean = c(0:6)
) %>% 
  mutate(
  output_lists = map(.x = pop_mean, ~rerun(5000, t_test_sim(mu = .x))),
  estimate_df = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_df)

```

```{r}
sim_results %>% 
  group_by(pop_mean) %>% 
  summarize(n_reject = sum(p_value < 0.05),
            prop_reject = n_reject/5000) %>% 
  ggplot(aes(x = pop_mean, y = prop_reject)) +
  geom_point() +
  labs(title = "True Mean vs. Proportion of Samples Rejected")
```

Association between effect size and power: the greater the effect size, the greater the power


```{r}
sim_results %>% 
  group_by(pop_mean) %>% 
  summarize(avg = mean(est_mean)) %>% 
  ggplot(aes(x = pop_mean, y = avg)) +
  geom_point() +
  labs(title = "True Mean vs. Average Estimated Mean",
       x = "True Mean Value",
       y = "Average Estimated Mean Value")
```

```{r}
sim_results %>% 
  filter(p_value < 0.05) %>% 
  group_by(pop_mean) %>% 
  summarize(avg = mean(est_mean)) %>% 
  ggplot(aes(x = pop_mean, y = avg)) +
  geom_point()
```

It appears that for most population mean values, the sample average of the estimated population mean is approximately equal to the true mean from which those values originated. This is because we are sampling from a normal distribution with a two-sided hypothesis test, meaning that approximately half of the sample means which reject the null will fall in the rejection region less than the true mean, and approximately half will fall in the rejection region greater than the true mean. This means that the average of all of the sample means which rejected the null will be quite close to the true population mean. Looking at the above plot, this holds true for population means of 0, 4, 5, and 6. For 1, 2, and 3, there were more points that were higher than the average leading them to be rejected.


